{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from new_semantic_parsing import utils\n",
    "from new_semantic_parsing import EncoderDecoderWPointerModel, Seq2SeqTrainer\n",
    "from new_semantic_parsing.schema_tokenizer import TopSchemaTokenizer\n",
    "from new_semantic_parsing.utils import compute_metrics, get_src_pointer_mask\n",
    "from new_semantic_parsing.data import PointerDataset, Seq2SeqDataCollator\n",
    "\n",
    "from cli.predict import make_test_dataset\n",
    "from cli.preprocess import make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '../output_dir/debug'\n",
    "TOKENIZER_PATH = '../output_dir/debug/tokenizer'\n",
    "DATA_PATH = '../data/top-dataset-semantic-parsing/eval.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-30 14:09:26 | INFO | transformers.configuration_utils | loading configuration file ../output_dir/debug/tokenizer/config.json\n",
      "2020-06-30 14:09:26 | INFO | transformers.configuration_utils | Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-06-30 14:09:26 | INFO | transformers.tokenization_utils | Model name '../output_dir/debug/tokenizer' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming '../output_dir/debug/tokenizer' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "2020-06-30 14:09:26 | INFO | transformers.tokenization_utils | Didn't find file ../output_dir/debug/tokenizer/added_tokens.json. We won't load it.\n",
      "2020-06-30 14:09:26 | INFO | transformers.tokenization_utils | loading file ../output_dir/debug/tokenizer/vocab.txt\n",
      "2020-06-30 14:09:26 | INFO | transformers.tokenization_utils | loading file None\n",
      "2020-06-30 14:09:26 | INFO | transformers.tokenization_utils | loading file ../output_dir/debug/tokenizer/special_tokens_map.json\n",
      "2020-06-30 14:09:26 | INFO | transformers.tokenization_utils | loading file ../output_dir/debug/tokenizer/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "schema_tokenizer = TopSchemaTokenizer.load(TOKENIZER_PATH)\n",
    "text_tokenizer: transformers.PreTrainedTokenizer = schema_tokenizer.src_tokenizer\n",
    "\n",
    "model = EncoderDecoderWPointerModel.from_pretrained(MODEL_PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f6246633824e6a999b02177c51a40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='tokenization', max=4462.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset: PointerDataset = make_test_dataset(DATA_PATH, text_tokenizer, max_len=63)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    collate_fn=Seq2SeqDataCollator(pad_id=text_tokenizer.pad_token_id).collate_batch,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam search (k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e884205ff8345ae948110d066992dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='generation', max=140.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "beam_search_preds_ids, beam_search_preds = utils.iterative_prediction(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    schema_tokenizer=schema_tokenizer,\n",
    "    max_len=63,\n",
    "    num_beams=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[IN:GET_EVENT what's to do ]\",\n",
       " '[IN:GET_EVENT What are they best place I could use to [SL:DESTINATION book a trip ] ]',\n",
       " '[IN:GET_EVENT Where can we take the [SL:DESTINATION [IN:GET_LOCATION [SL:LOCATION kids ] ] ] ]',\n",
       " '[IN:GET_EVENT Any [SL:DATE_TIME festivals ] [SL:DATE_TIME this weekend ] ]',\n",
       " '[IN:GET_EVENT Are there any [SL:DATE_TIME Christmas parties ] [SL:DATE_TIME this weekend ] ]',\n",
       " \"[IN:GET_ESTIMATED_DURATION I need a restaurant that seems classy but is really [SL:DESTINATION [IN:GET_LOCATION [SL:DESTINATION Manhattan but doesn't require dinner time reservations ] ' t require dinner time reservations ] but doesn't require dinner time reservations [SL:DESTINATION Manhattan but doesn't require dinner time reservations ]\",\n",
       " '[IN:GET_EVENT Any [SL:CATEGORY_EVENT live music events ] on [SL:DATE_TIME friday ] ]',\n",
       " '[IN:GET_EVENT [SL:CATEGORY_EVENT concerts ] by [SL:LOCATION sia ] ]',\n",
       " '[IN:GET_INFO_TRAFFIC when is the [SL:DATE_TIME next showing of the nutcracker ] ]',\n",
       " '[IN:GET_EVENT What is going on [SL:DATE_TIME right now ] ]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputDataClass(input_ids=tensor([ 101, 1184,  112,  188, 1106, 1202,  102]), decoder_input_ids=None, attention_mask=None, decoder_attention_mask=None, pointer_mask=tensor([0., 1., 1., 1., 1., 1., 0.]), decoder_pointer_mask=None, labels=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex = dataset[0]\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101, 1184,  112,  188, 1106, 1202,  102]]) \n",
      " tensor([[0., 1., 1., 1., 1., 1., 0.]]) \n",
      " tensor([[1]])\n"
     ]
    }
   ],
   "source": [
    "input_ids = ex.input_ids.unsqueeze(0)\n",
    "pointer_mask = ex.pointer_mask.unsqueeze(0)\n",
    "decoder_input_ids = (torch.ones(1, 1) * schema_tokenizer.bos_token_id).long()\n",
    "\n",
    "print(input_ids,'\\n', pointer_mask, '\\n', decoder_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 74])\n",
      "67 7\n"
     ]
    }
   ],
   "source": [
    "out = model(input_ids=input_ids, pointer_mask=pointer_mask, decoder_input_ids=decoder_input_ids)\n",
    "logits = out[0]\n",
    "print(logits.shape)\n",
    "print(schema_tokenizer.vocab_size, input_ids.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[65]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_symb = logits.max(-1).indices\n",
    "next_symb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_ids = torch.cat([decoder_input_ids, next_symb], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_symb.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 74])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[:, -1, :].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 65, 34, 21, 68, 69, 70, 71, 72, 66])\n",
      "[BOS] [IN:GET_EVENT what's to do ]\n"
     ]
    }
   ],
   "source": [
    "input_ids = ex.input_ids.unsqueeze(0)\n",
    "pointer_mask = ex.pointer_mask.unsqueeze(0)\n",
    "decoder_input_ids = (torch.ones(1, 1) * schema_tokenizer.bos_token_id).long()\n",
    "\n",
    "for _ in range(63):\n",
    "    out = model(input_ids=input_ids, pointer_mask=pointer_mask, decoder_input_ids=decoder_input_ids)\n",
    "    logits = out[0]\n",
    "\n",
    "    next_symb = logits[:, -1, :].max(-1).indices.unsqueeze(1)\n",
    "\n",
    "    if next_symb.item() in [schema_tokenizer.eos_token_id, schema_tokenizer.pad_token_id]:\n",
    "        break\n",
    "    \n",
    "    decoder_input_ids = torch.cat([decoder_input_ids, next_symb], axis=-1)\n",
    "\n",
    "print(decoder_input_ids.squeeze())\n",
    "print(schema_tokenizer.decode(decoder_input_ids.squeeze(), input_ids.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[65, 34]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_symb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy search\n",
    "\n",
    "maximally simple implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_greedy_prediction(model, dataset, schema_tokenizer, max_len):\n",
    "    # we use dataset instead of dataloader here to simplify stuff\n",
    "\n",
    "    predictions_ids = []\n",
    "    predictions_str = []\n",
    "\n",
    "    for i, ex in enumerate(tqdm(dataset, desc='prediction')):\n",
    "        input_ids = ex.input_ids.unsqueeze(0)\n",
    "        pointer_mask = ex.pointer_mask.unsqueeze(0)\n",
    "        decoder_input_ids = (torch.ones(1, 1) * schema_tokenizer.bos_token_id).long()\n",
    "\n",
    "        for _ in range(63):\n",
    "            out = model(input_ids=input_ids, pointer_mask=pointer_mask, decoder_input_ids=decoder_input_ids)\n",
    "            logits = out[0]\n",
    "\n",
    "            next_symb = logits[:, -1, :].max(-1).indices.unsqueeze(1)\n",
    "\n",
    "            decoder_input_ids = torch.cat([decoder_input_ids, next_symb], axis=-1)\n",
    "            \n",
    "            if next_symb.item() in [schema_tokenizer.eos_token_id, schema_tokenizer.pad_token_id]:\n",
    "                break\n",
    "\n",
    "\n",
    "        prediction = decoder_input_ids.squeeze()[1:]\n",
    "        predictions_ids.append(prediction)\n",
    "        predictions_str.append(schema_tokenizer.decode(prediction, input_ids.squeeze(), skip_special_tokens=True))\n",
    "\n",
    "    return predictions_ids, predictions_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555f633d021d4c0ab397c0b1bbc5ede0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='prediction', max=4462.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "greedy_preds_ids, greedy_preds = iterative_greedy_prediction(model, dataset, schema_tokenizer, 63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam-1 vs greedy\n",
    "\n",
    "sanity check passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[IN:GET_EVENT what's to do ]\",\n",
       " '[IN:GET_EVENT What are they best place I could use to [SL:DESTINATION book a trip ] ]',\n",
       " '[IN:GET_EVENT Where can we take the [SL:DESTINATION [IN:GET_LOCATION [SL:LOCATION kids ] ] ] ]',\n",
       " '[IN:GET_EVENT Any [SL:DATE_TIME festivals ] [SL:DATE_TIME this weekend ] ]',\n",
       " '[IN:GET_EVENT Are there any [SL:DATE_TIME Christmas parties ] [SL:DATE_TIME this weekend ] ]',\n",
       " \"[IN:GET_ESTIMATED_DURATION I need a restaurant that seems classy but is really [SL:DESTINATION [IN:GET_LOCATION [SL:DESTINATION Manhattan but doesn't require dinner time reservations ] ' t require dinner time reservations ] but doesn't require dinner time reservations [SL:DESTINATION Manhattan but doesn't require dinner time reservations ]\",\n",
       " '[IN:GET_EVENT Any [SL:CATEGORY_EVENT live music events ] on [SL:DATE_TIME friday ] ]',\n",
       " '[IN:GET_EVENT [SL:CATEGORY_EVENT concerts ] by [SL:LOCATION sia ] ]',\n",
       " '[IN:GET_INFO_TRAFFIC when is the [SL:DATE_TIME next showing of the nutcracker ] ]',\n",
       " '[IN:GET_EVENT What is going on [SL:DATE_TIME right now ] ]']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[IN:GET_EVENT what's to do ]\",\n",
       " '[IN:GET_EVENT What are they best place I could use to [SL:DESTINATION book a trip ] ]',\n",
       " '[IN:GET_EVENT Where can we take the [SL:DESTINATION [IN:GET_LOCATION [SL:LOCATION kids ] ] ] ]',\n",
       " '[IN:GET_EVENT Any [SL:DATE_TIME festivals ] [SL:DATE_TIME this weekend ] ]',\n",
       " '[IN:GET_EVENT Are there any [SL:DATE_TIME Christmas parties ] [SL:DATE_TIME this weekend ] ]',\n",
       " \"[IN:GET_ESTIMATED_DURATION I need a restaurant that seems classy but is really [SL:DESTINATION [IN:GET_LOCATION [SL:DESTINATION Manhattan but doesn't require dinner time reservations ] ' t require dinner time reservations ] but doesn't require dinner time reservations [SL:DESTINATION Manhattan but doesn't require dinner time reservations ]\",\n",
       " '[IN:GET_EVENT Any [SL:CATEGORY_EVENT live music events ] on [SL:DATE_TIME friday ] ]',\n",
       " '[IN:GET_EVENT [SL:CATEGORY_EVENT concerts ] by [SL:LOCATION sia ] ]',\n",
       " '[IN:GET_INFO_TRAFFIC when is the [SL:DATE_TIME next showing of the nutcracker ] ]',\n",
       " '[IN:GET_EVENT What is going on [SL:DATE_TIME right now ] ]']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search_preds == greedy_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_errors = 0\n",
    "_beam_search_preds = beam_search_preds\n",
    "_beam_search_preds_ids = beam_search_preds_ids\n",
    "\n",
    "for i in range(len(beam_search_preds)):\n",
    "    if _beam_search_preds[i] != greedy_preds[i]:\n",
    "        n_errors += 1\n",
    "        print('Mismatch ', n_errors)\n",
    "        print(f'Beam-1: ', _beam_search_preds[i])\n",
    "        print('Greedy len: ', len(greedy_preds_ids[i]), 'Beam-1 len: ', len(_beam_search_preds_ids[i]))\n",
    "        print(f'Greedy: ', greedy_preds[i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4462/4462 [00:00<00:00, 5113.48it/s]\n",
      "100%|██████████| 4462/4462 [00:02<00:00, 1736.62it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_with_labels: PointerDataset = make_dataset(DATA_PATH, text_tokenizer, schema_tokenizer)\n",
    "dataloader_with_labels = torch.utils.data.DataLoader(\n",
    "    dataset_with_labels,\n",
    "    batch_size=32,\n",
    "    collate_fn=Seq2SeqDataCollator(pad_id=text_tokenizer.pad_token_id).collate_batch,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teacher_forcing_prediction(model, dataset, schema_tokenizer, max_len):\n",
    "    # we use dataset instead of dataloader here to simplify stuff\n",
    "\n",
    "    predictions_ids = []\n",
    "    predictions_str = []\n",
    "\n",
    "    for i, ex in enumerate(tqdm(dataset, desc='prediction')):\n",
    "        input_ids = ex.input_ids.unsqueeze(0)\n",
    "        pointer_mask = ex.pointer_mask.unsqueeze(0)\n",
    "        decoder_input_ids = ex.decoder_input_ids.unsqueeze(0)\n",
    "\n",
    "        out = model(input_ids=input_ids, pointer_mask=pointer_mask, decoder_input_ids=decoder_input_ids)\n",
    "        logits = out[0]\n",
    "        prediction = logits.squeeze().max(-1).indices\n",
    "\n",
    "        predictions_ids.append(prediction)\n",
    "        predictions_str.append(schema_tokenizer.decode(prediction, input_ids.squeeze(), skip_special_tokens=True))\n",
    "\n",
    "    return predictions_ids, predictions_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d822c7857f4ab79f67e0547002475d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='prediction', max=4462.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tf_preds_ids, tf_preds = teacher_forcing_prediction(model, dataset_with_labels, schema_tokenizer, 63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacher forced EM vs gready EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([65, 34, 21, 68, 69, 70, 71, 72, 66,  2])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_preds_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensors_equal(t1, t2):\n",
    "    # strip EOS token\n",
    "    if t1[-1] == 2:\n",
    "        t1 = t1[:-1]\n",
    "    if t2[-1] == 2:\n",
    "        t2 = t2[:-1]\n",
    "\n",
    "    return int(t1.shape == t2.shape and torch.all(t1 == t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303 303\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "tf_em = sum(tensors_equal(pred, ex.labels) for pred, ex in zip(tf_preds_ids, dataset_with_labels))\n",
    "greedy_em = sum(tensors_equal(pred, ex.labels) for pred, ex in zip(greedy_preds_ids, dataset_with_labels))\n",
    "\n",
    "print(tf_em, greedy_em)\n",
    "print(tf_em == greedy_em)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing decoded strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"[IN:GET_EVENT what 's to do ]\",\n",
       " '[IN:UNSUPPORTED What are they best place I could use to book a trip ]',\n",
       " '[IN:GET_EVENT Where can we take [SL:ATTRIBUTE_EVENT the kids ] ]']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_df = pd.read_table(DATA_PATH, names=['text', 'tokens', 'schema'])\n",
    "targets_str = list(data_df.schema)\n",
    "targets_str[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274 273\n"
     ]
    }
   ],
   "source": [
    "tf_em = sum(int(pred == target) for pred, target in zip(tf_preds, targets_str))\n",
    "greedy_em = sum(int(pred == target) for pred, target in zip(greedy_preds, targets_str))\n",
    "\n",
    "print(tf_em, greedy_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traget:  [IN:GET_EVENT [SL:CATEGORY_EVENT College events ] ]\n",
      "Forced:  [IN:GET_EVENT [SL:CATEGORY_EVENT College events ] ]\n",
      "Greedy:  [IN:GET_EVENT [SL:CATEGORY_EVENT College events ] ] events [SL:DESTINATION [IN:GET_LOCATION [SL:LOCATION [IN:GET_LOCATION [SL:LOCATION [IN:GET_LOCATION [SL:LOCATION ] ] ] ] ] ] ] ] ]\n"
     ]
    }
   ],
   "source": [
    "tf_matches = [int(pred == target) for pred, target in zip(tf_preds, targets_str)]\n",
    "greedy_matches = [int(pred == target) for pred, target in zip(greedy_preds, targets_str)]\n",
    "\n",
    "delta = [i for i, (x, y) in enumerate(zip(tf_matches, greedy_matches)) if x != y]\n",
    "\n",
    "for d in delta:\n",
    "    print('Traget: ', targets_str[d])\n",
    "    print('Forced: ', tf_preds[d])\n",
    "    print('Greedy: ', greedy_preds[d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^ makes sence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The issue\n",
    "\n",
    "decoding back to text breaks something, probably it merges tokens like \"what 's\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch  1\n",
      "Target str:  [IN:GET_EVENT what 's to do ]\n",
      "Decoded   :  [IN:GET_EVENT what's to do ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 72, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 72, 66,  2])\n",
      "\n",
      "Mismatch  2\n",
      "Target str:  [IN:GET_EVENT What 's going on [SL:DATE_TIME Saturday ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's going on [SL:DATE_TIME Saturday ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 72, 65, 53, 11, 73, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 72, 65, 53, 11, 73, 66, 66,  2])\n",
      "\n",
      "Mismatch  3\n",
      "Target str:  [IN:GET_EVENT What 's going on [SL:DATE_TIME today ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's going on [SL:DATE_TIME today ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 72, 65, 53, 11, 73, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 72, 65, 53, 11, 73, 66, 66,  2])\n",
      "\n",
      "Mismatch  4\n",
      "Target str:  [IN:GET_EVENT What 's going on [SL:DATE_TIME tonight ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's going on [SL:DATE_TIME tonight ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 72, 65, 53, 11, 73, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 72, 65, 53, 11, 73, 66, 66,  2])\n",
      "\n",
      "Mismatch  5\n",
      "Target str:  [IN:GET_EVENT What 's up [SL:DATE_TIME tonight ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's up [SL:DATE_TIME tonight ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 66, 66,  2])\n",
      "\n",
      "Mismatch  6\n",
      "Target str:  [IN:GET_EVENT What 's to do in [SL:LOCATION Frisco TX ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's to do in [SL:LOCATION Frisco TX ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 75, 76, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 75, 76, 66, 66,  2])\n",
      "\n",
      "Mismatch  7\n",
      "Target str:  [IN:GET_EVENT What 's going on in [SL:LOCATION Atlantic City ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's going on in [SL:LOCATION Atlantic City ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 75, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 75, 66, 66,  2])\n",
      "\n",
      "Mismatch  8\n",
      "Target str:  [IN:GET_EVENT [SL:CATEGORY_EVENT Women 's Aglow meetings ] ]\n",
      "Decoded   :  [IN:GET_EVENT [SL:CATEGORY_EVENT Women's Aglow meetings ] ]\n",
      "Target ids :  tensor([65, 34, 21, 65, 53,  6, 68, 69, 70, 71, 72, 73, 74, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 65, 53,  6, 68, 69, 70, 71, 72, 73, 74, 66, 66,  2])\n",
      "\n",
      "Mismatch  9\n",
      "Target str:  [IN:GET_EVENT What 's happening [SL:DATE_TIME this weekend ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's happening [SL:DATE_TIME this weekend ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 73, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 73, 66, 66,  2])\n",
      "\n",
      "Mismatch  10\n",
      "Target str:  [IN:GET_EVENT What can I do [SL:DATE_TIME tonight ] that 's fun ]\n",
      "Decoded   :  [IN:GET_EVENT What can I do [SL:DATE_TIME tonight ] that's fun ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 66, 73, 74, 75, 76, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 66, 73, 74, 75, 76, 66,  2])\n",
      "\n",
      "Mismatch  11\n",
      "Target str:  [IN:GET_EVENT What 's happening [SL:DATE_TIME this weekend ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's happening [SL:DATE_TIME this weekend ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 73, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 73, 66, 66,  2])\n",
      "\n",
      "Mismatch  12\n",
      "Target str:  [IN:GET_EVENT What 's happening [SL:DATE_TIME this weekend ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's happening [SL:DATE_TIME this weekend ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 73, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 73, 66, 66,  2])\n",
      "\n",
      "Mismatch  13\n",
      "Target str:  [IN:GET_EVENT What 's going on [SL:DATE_TIME tonight ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's going on [SL:DATE_TIME tonight ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 72, 65, 53, 11, 73, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 72, 65, 53, 11, 73, 66, 66,  2])\n",
      "\n",
      "Mismatch  14\n",
      "Target str:  [IN:GET_EVENT What 's happening [SL:DATE_TIME this weekend ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's happening [SL:DATE_TIME this weekend ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 73, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 73, 66, 66,  2])\n",
      "\n",
      "Mismatch  15\n",
      "Target str:  [IN:GET_EVENT What 's happening [SL:DATE_TIME today ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's happening [SL:DATE_TIME today ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 65, 53, 11, 72, 66, 66,  2])\n",
      "\n",
      "Mismatch  16\n",
      "Target str:  [IN:GET_EVENT Events in [SL:LOCATION St . Louis ] ]\n",
      "Decoded   :  [IN:GET_EVENT Events in [SL:LOCATION St. Louis ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 65, 53, 35, 70, 71, 72, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 65, 53, 35, 70, 71, 72, 66, 66,  2])\n",
      "\n",
      "Mismatch  17\n",
      "Target str:  [IN:GET_EVENT What 's going on in [SL:LOCATION New Berlin ] ]\n",
      "Decoded   :  [IN:GET_EVENT What's going on in [SL:LOCATION New Berlin ] ]\n",
      "Target ids :  tensor([65, 34, 21, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 75, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 21, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 75, 66, 66,  2])\n",
      "\n",
      "Mismatch  18\n",
      "Target str:  [IN:GET_EVENT [SL:CATEGORY_EVENT Music events ] in [SL:LOCATION Zagreb , Croatia ] ]\n",
      "Decoded   :  [IN:GET_EVENT [SL:CATEGORY_EVENT Music events ] in [SL:LOCATION Zagreb, Croatia ] ]\n",
      "Target ids :  tensor([65, 34, 21, 65, 53,  6, 68, 69, 66, 70, 65, 53, 35, 71, 72, 73, 66, 66,\n",
      "         2])\n",
      "Predictions:  tensor([65, 34, 21, 65, 53,  6, 68, 69, 66, 70, 65, 53, 35, 71, 72, 73, 66, 66,\n",
      "         2])\n",
      "\n",
      "Mismatch  19\n",
      "Target str:  [IN:GET_INFO_TRAFFIC What 's the traffic in [SL:LOCATION Lakeland ] ]\n",
      "Decoded   :  [IN:GET_INFO_TRAFFIC What's the traffic in [SL:LOCATION Lakeland ] ]\n",
      "Target ids :  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 75, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 75, 66, 66,  2])\n",
      "\n",
      "Mismatch  20\n",
      "Target str:  [IN:GET_INFO_TRAFFIC how 's the traffic [SL:DATE_TIME tonight ] ]\n",
      "Decoded   :  [IN:GET_INFO_TRAFFIC how's the traffic [SL:DATE_TIME tonight ] ]\n",
      "Target ids :  tensor([65, 34, 27, 68, 69, 70, 71, 72, 65, 53, 11, 73, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 27, 68, 69, 70, 71, 72, 65, 53, 11, 73, 66, 66,  2])\n",
      "\n",
      "Mismatch  21\n",
      "Target str:  [IN:GET_INFO_TRAFFIC How 's the traffic ]\n",
      "Decoded   :  [IN:GET_INFO_TRAFFIC How's the traffic ]\n",
      "Target ids :  tensor([65, 34, 27, 68, 69, 70, 71, 72, 66,  2])\n",
      "Predictions:  tensor([65, 34, 27, 68, 69, 70, 71, 72, 66,  2])\n",
      "\n",
      "Mismatch  22\n",
      "Target str:  [IN:GET_ESTIMATED_DURATION How long is it to [SL:DESTINATION Buffalo , New York ] ]\n",
      "Decoded   :  [IN:GET_ESTIMATED_DURATION How long is it to [SL:DESTINATION Buffalo, New York ] ]\n",
      "Target ids :  tensor([65, 34, 20, 68, 69, 70, 71, 72, 65, 53, 14, 73, 74, 75, 76, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 20, 68, 69, 70, 71, 72, 65, 53, 14, 73, 74, 75, 76, 66, 66,  2])\n",
      "\n",
      "Mismatch  23\n",
      "Target str:  [IN:GET_ESTIMATED_DURATION How long will it take me to get to [SL:DESTINATION Jackson , Mississippi ] ]\n",
      "Decoded   :  [IN:GET_ESTIMATED_DURATION How long will it take me to get to [SL:DESTINATION Jackson, Mississippi ] ]\n",
      "Target ids :  tensor([65, 34, 20, 68, 69, 70, 71, 72, 73, 74, 75, 76, 65, 53, 14, 77, 78, 79,\n",
      "        66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 20, 68, 69, 70, 71, 72, 73, 74, 75, 76, 65, 53, 14, 77, 78, 79,\n",
      "        66, 66,  2])\n",
      "\n",
      "Mismatch  24\n",
      "Target str:  [IN:GET_INFO_TRAFFIC how 's traffic looking ]\n",
      "Decoded   :  [IN:GET_INFO_TRAFFIC how's traffic looking ]\n",
      "Target ids :  tensor([65, 34, 27, 68, 69, 70, 71, 72, 66,  2])\n",
      "Predictions:  tensor([65, 34, 27, 68, 69, 70, 71, 72, 66,  2])\n",
      "\n",
      "Mismatch  25\n",
      "Target str:  [IN:GET_INFO_TRAFFIC What 's the traffic on [SL:LOCATION 144th street ] ]\n",
      "Decoded   :  [IN:GET_INFO_TRAFFIC What's the traffic on [SL:LOCATION 144th street ] ]\n",
      "Target ids :  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 75, 76, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 75, 76, 66, 66,  2])\n",
      "\n",
      "Mismatch  26\n",
      "Target str:  [IN:GET_INFO_TRAFFIC How does the traffic look going to [SL:DESTINATION Sarasota , Florida ] ]\n",
      "Decoded   :  [IN:GET_INFO_TRAFFIC How does the traffic look going to [SL:DESTINATION Sarasota, Florida ] ]\n",
      "Target ids :  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 74, 65, 53, 14, 75, 76, 77, 78, 79,\n",
      "        66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 74, 65, 53, 14, 75, 76, 77, 78, 79,\n",
      "        66, 66,  2])\n",
      "\n",
      "Mismatch  27\n",
      "Target str:  [IN:GET_INFO_TRAFFIC what 's the traffic like to [SL:DESTINATION kenosha ] [SL:DATE_TIME right now ] ]\n",
      "Decoded   :  [IN:GET_INFO_TRAFFIC what's the traffic like to [SL:DESTINATION kenosha ] [SL:DATE_TIME right now ] ]\n",
      "Target ids :  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 74, 65, 53, 14, 75, 76, 77, 66, 65,\n",
      "        53, 11, 78, 79, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 74, 65, 53, 14, 75, 76, 77, 66, 65,\n",
      "        53, 11, 78, 79, 66, 66,  2])\n",
      "\n",
      "Mismatch  28\n",
      "Target str:  [IN:GET_INFO_TRAFFIC Tell me if there 's any bad traffic ]\n",
      "Decoded   :  [IN:GET_INFO_TRAFFIC Tell me if there's any bad traffic ]\n",
      "Target ids :  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 74, 75, 76, 66,  2])\n",
      "Predictions:  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 74, 75, 76, 66,  2])\n",
      "\n",
      "Mismatch  29\n",
      "Target str:  [IN:GET_INFO_TRAFFIC How 's the traffic in [SL:LOCATION Cincinnati ] ]\n",
      "Decoded   :  [IN:GET_INFO_TRAFFIC How's the traffic in [SL:LOCATION Cincinnati ] ]\n",
      "Target ids :  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 66, 66,  2])\n",
      "\n",
      "Mismatch  30\n",
      "Target str:  [IN:GET_INFO_TRAFFIC What 's the traffic in [SL:LOCATION LA ] ]\n",
      "Decoded   :  [IN:GET_INFO_TRAFFIC What's the traffic in [SL:LOCATION LA ] ]\n",
      "Target ids :  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 66, 66,  2])\n",
      "Predictions:  tensor([65, 34, 27, 68, 69, 70, 71, 72, 73, 65, 53, 35, 74, 66, 66,  2])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_errors = 0\n",
    "\n",
    "ids_preds = tf_preds_ids\n",
    "decoded_preds = tf_preds\n",
    "\n",
    "for i in range(len(targets_str)):\n",
    "    if tensors_equal(ids_preds[i], dataset_with_labels[i].labels) and decoded_preds[i] != targets_str[i]:\n",
    "        n_errors += 1\n",
    "        print('Mismatch ', n_errors)\n",
    "\n",
    "        print('Target str: ', targets_str[i])\n",
    "        print('Decoded   : ', decoded_preds[i])\n",
    "\n",
    "        print('Target ids : ', dataset_with_labels[i].labels)\n",
    "        print('Predictions: ', ids_preds[i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~~Solution~~ Crutch: postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_postprocess(predicted_str):\n",
    "    predicted_str = predicted_str.replace(\"'s\", \" 's\")\n",
    "    predicted_str = predicted_str.replace(\".\", \" .\")\n",
    "    predicted_str = predicted_str.replace(\",\", \" ,\")\n",
    "    predicted_str = predicted_str.replace(\"?\", \" ?\")\n",
    "    predicted_str = predicted_str.replace(\"!\", \" !\")\n",
    "    return predicted_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPD: More complicated version of the function above works most of the time (0.997), but not always"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hooray!\n"
     ]
    }
   ],
   "source": [
    "n_errors = 0\n",
    "\n",
    "ids_preds = tf_preds_ids\n",
    "decoded_preds = [top_postprocess(p) for p in tf_preds]\n",
    "\n",
    "for i in range(len(targets_str)):\n",
    "    if tensors_equal(ids_preds[i], dataset_with_labels[i].labels) and decoded_preds[i] != targets_str[i]:\n",
    "        n_errors += 1\n",
    "        print('Mismatch ', n_errors)\n",
    "\n",
    "        print('Target str: ', targets_str[i])\n",
    "        print('Decoded   : ', decoded_preds[i])\n",
    "\n",
    "        print('Target ids : ', dataset_with_labels[i].labels)\n",
    "        print('Predictions: ', ids_preds[i])\n",
    "        print()\n",
    "\n",
    "if n_errors == 0:\n",
    "    print('Hooray!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
